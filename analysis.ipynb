{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcca Calgary HTTP Log Analysis\n", "This notebook contains the solution to the take-home assessment for analyzing the Calgary HTTP web server logs using Python."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# \ud83d\udce5 Step 1: Load and Read the .gz File\n", "import gzip\n", "log_lines = []\n", "with gzip.open(\"calgary_access_log.gz\", 'rt', encoding='utf-8', errors='ignore') as f:\n", "    log_lines = f.readlines()\n", "print(\"Total lines:\", len(log_lines))"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# \ud83d\udce6 Step 2: Parse Logs\n", "import re\n", "from datetime import datetime\n", "import pandas as pd\n", "\n", "log_pattern = re.compile(\n", "    r'(?P<host>\\S+) \\S+ \\S+ \\[(?P<timestamp>.*?)\\] \"(?:GET|POST) (?P<filename>\\S+) \\S+\" (?P<status>\\d{3}) (?P<bytes>\\S+)'\n", ")\n", "\n", "parsed_logs = []\n", "for line in log_lines:\n", "    match = log_pattern.match(line)\n", "    if match:\n", "        data = match.groupdict()\n", "        try:\n", "            data['datetime'] = datetime.strptime(data['timestamp'], \"%d/%b/%Y:%H:%M:%S %z\")\n", "        except:\n", "            continue\n", "        data['bytes'] = int(data['bytes']) if data['bytes'].isdigit() else 0\n", "        data['status'] = int(data['status'])\n", "        parsed_logs.append(data)\n", "\n", "df = pd.DataFrame(parsed_logs)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u2705 Analysis Questions"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q1: Total number of log records\n", "len(df)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q2: Unique hosts\n", "df['host'].nunique()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q3: Date-wise unique filename counts\n", "df['date'] = df['datetime'].dt.strftime('%d-%b-%Y')\n", "df.groupby('date')['filename'].nunique().to_dict()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q4: Number of 404 responses\n", "(df['status'] == 404).sum()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q5: Top 15 filenames with 404 responses\n", "df_404 = df[df['status'] == 404]\n", "df_404['filename'].value_counts().head(15).items()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q6: Top 15 extensions with 404 responses\n", "df_404['extension'] = df_404['filename'].apply(lambda x: x.split('.')[-1] if '.' in x else 'none')\n", "df_404['extension'].value_counts().head(15).items()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q7: Total bandwidth transferred per day for July 1995\n", "july_df = df[(df['datetime'].dt.month == 7) & (df['datetime'].dt.year == 1995)]\n", "july_df.groupby(july_df['date'])['bytes'].sum().to_dict()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q8: Hourly request distribution\n", "df['hour'] = df['datetime'].dt.hour\n", "df.groupby('hour').size().to_dict()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q9: Top 10 most requested filenames\n", "df['filename'].value_counts().head(10).items()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Q10: HTTP response code distribution\n", "df['status'].value_counts().to_dict()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 2}